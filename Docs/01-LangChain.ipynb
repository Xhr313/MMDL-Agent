{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa220434-104b-44ca-97bc-35011fe69c08",
   "metadata": {},
   "source": [
    "# ğŸŒŸ LangChain å…¥é—¨ä¸å®æˆ˜æ•™ç¨‹\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ\n",
    "\n",
    "**LangChain** æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨æ¡†æ¶ã€‚  \n",
    "å®ƒçš„æ ¸å¿ƒç›®æ ‡æ˜¯ â€”â€”  \n",
    "> è®©æˆ‘ä»¬èƒ½åƒâ€œæ­ç§¯æœ¨â€ä¸€æ ·ï¼ŒæŠŠ LLMã€Promptã€Memoryã€Toolã€Database ç­‰æ¨¡å—**ç»„åˆæˆä¸€ä¸ªå®Œæ•´ç³»ç»Ÿ**ã€‚\n",
    "\n",
    "æ¢å¥è¯è¯´ï¼ŒLangChain è®© AI ä¸å†åªæ˜¯â€œèŠå¤©â€ï¼Œ  \n",
    "è€Œæ˜¯èƒ½**è®°å¿†ã€æ¨ç†ã€æ£€ç´¢ã€è°ƒç”¨å·¥å…·**ã€æ‰§è¡Œå®Œæ•´é€»è¾‘ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© LangChain çš„æ ¸å¿ƒç»„ä»¶\n",
    "\n",
    "| æ¨¡å— | ä½œç”¨ | ç¤ºä¾‹ |\n",
    "|------|------|------|\n",
    "| **Prompt** | è®¾å®šæç¤ºæ¨¡æ¿ | â€œè¯·åˆ†æä»¥ä¸‹æ–‡æœ¬æƒ…æ„Ÿï¼š{text}â€ |\n",
    "| **LLM** | è°ƒç”¨å¤§æ¨¡å‹ï¼ˆå¦‚ OpenAIã€Qwenã€Claudeï¼‰ | `ChatOpenAI()` |\n",
    "| **Parser** | è§£ææ¨¡å‹è¾“å‡ºä¸ºç»“æ„åŒ–ç»“æœ | `StrOutputParser()`ã€`with_structured_output()` |\n",
    "| **Chain (LCEL)** | ç”¨ç®¡é“ç¬¦æŠŠå„æ¨¡å—ä¸²è”èµ·æ¥ | Prompt - LLM -  Parser\n",
    "| **Memory** | ä¿å­˜å†å²å¯¹è¯ï¼Œå®ç°ä¸Šä¸‹æ–‡è®°å¿† | `RunnableWithMessageHistory()` |\n",
    "| **Tool** | å·¥å…·è°ƒç”¨ï¼Œä¾‹å¦‚è®¡ç®—ã€æŸ¥å¤©æ°” | `@tool` |\n",
    "| **RAG** | æ£€ç´¢å¢å¼ºé—®ç­”ï¼Œç»“åˆå‘é‡æ•°æ®åº“ | FAISS / Chroma |\n",
    "| **Fallback** | æ¨¡å‹æˆ–é“¾å‡ºé”™æ—¶çš„è‡ªåŠ¨å›é€€ | `.with_fallbacks()` |\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ LangChain Expression Languageï¼ˆLCELï¼‰\n",
    "\n",
    "LangChain 2.0 å¼•å…¥äº†æ–°çš„â€œè¡¨è¾¾å¼è¯­è¨€â€ â€”â€” **LCEL**ï¼Œ  \n",
    "ç”¨ä¸€ä¸ªç¬¦å· `|` ä¸²è”æ•´ä¸ªæµç¨‹ï¼Œè®©é“¾å¼é€»è¾‘æ›´æ¸…æ™°ï¼š\n",
    "\n",
    "```python\n",
    "ChatPromptTemplate.from_template(\"é—®é¢˜ï¼š{question}\") \n",
    "| llm \n",
    "| StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79795fc1-6b30-4c1b-b7d9-eb0ca16e6f02",
   "metadata": {},
   "source": [
    "# 1. LCEL æœ€ç®€å•çš„é—®ç­”é“¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a95f10-c5d3-4380-aad0-ba963457a845",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'pytorch (Python 3.11.14)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "æœ€ç®€å•çš„ LCEL é—®ç­”\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# å®šä¹‰æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    base_url=\"https://www.dmxapi.cn/v1\",\n",
    "    api_key=\"xxx\", # æ›¿æ¢ä¸ºä½ çš„ API Key \n",
    "    temperature=0)\n",
    "\n",
    "# æ„å»ºé“¾ï¼šPrompt -> LLM -> è§£ææ–‡æœ¬\n",
    "qa_chain = (\n",
    "    ChatPromptTemplate.from_template(\"ç”¨æˆ·é—®é¢˜ï¼š{question}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œé—®ç­”\n",
    "if __name__ == \"__main__\":\n",
    "    result = qa_chain.invoke({\"question\": \"ä¸­å›½çš„é¦–éƒ½æ˜¯å“ªï¼Ÿ\"})\n",
    "    print(\"AIç­”å¤ï¼š\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429a5b3d-fc3f-4a0d-ba25-9bd51cf6f8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "567736a1-bf66-4376-a956-26fe8c35709f",
   "metadata": {},
   "source": [
    "# 2. ç»“æ„åŒ–è¾“å‡ºï¼ˆPydantic Schemaï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040576f-e1c3-44b5-ad27-451b1d1b0b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': 'ç§¯æ', 'topic': 'è‚¡å¸‚è¡¨ç°ä¸æŠ•èµ„ä¿¡å¿ƒ', 'summary': 'ä»Šå¤©è‚¡å¸‚è¡¨ç°è‰¯å¥½ï¼Œä½œè€…å¯¹æœªæ¥çš„æŠ•èµ„æŒä¹è§‚æ€åº¦ã€‚'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_948/3080188056.py:35: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(result.dict())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "LCEL æ ¼å¼åŒ–è¾“å‡ºæ¡ˆä¾‹ï¼š\n",
    "è¾“å…¥ä¸€æ®µæ–‡æœ¬ â†’ è¿”å›ç»“æ„åŒ–ç»“æœï¼ˆæƒ…æ„Ÿåˆ†ç±» + ä¸»é¢˜ + æ€»ç»“ï¼‰\n",
    "\"\"\"\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. å®šä¹‰è¾“å‡º Schema\n",
    "class AnalysisResult(BaseModel):\n",
    "    sentiment: Literal[\"ç§¯æ\", \"ä¸­æ€§\", \"æ¶ˆæ\"] = Field(..., description=\"æ–‡æœ¬çš„æƒ…æ„Ÿææ€§\")\n",
    "    topic: str = Field(..., description=\"ä¸»è¦ä¸»é¢˜\")\n",
    "    summary: str = Field(..., description=\"ç®€è¦æ€»ç»“\")\n",
    "\n",
    "# 2. å®šä¹‰æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    base_url=\"https://www.dmxapi.cn/v1\",\n",
    "    #api_key=\"\",  æ›¿æ¢ä¸ºä½ çš„ API Key \n",
    "    temperature=0)\n",
    "\n",
    "# 3. æ„å»º LCEL é“¾ï¼šPrompt | LLM | StructuredOutput\n",
    "analysis_chain = (\n",
    "    ChatPromptTemplate.from_template(\"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯ï¼š{text}\")\n",
    "    | llm.with_structured_output(AnalysisResult)\n",
    ")\n",
    "\n",
    "# 4. æ‰§è¡Œ\n",
    "if __name__ == \"__main__\":\n",
    "    result: AnalysisResult = analysis_chain.invoke(\n",
    "        {\"text\": \"ä»Šå¤©è‚¡å¸‚å¤§æ¶¨ï¼Œæˆ‘å¯¹æœªæ¥çš„æŠ•èµ„å……æ»¡ä¿¡å¿ƒï¼\"}\n",
    "    )\n",
    "    print(result.dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b866d33-ac78-45cf-977a-4dbe345b0b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf0c25a3-6c83-40ac-a9b0-5a91ff2786af",
   "metadata": {},
   "source": [
    "# 3. å†å²è®°å¿†ä¸æ¶ˆæ¯å ä½ç¬¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d88e1-1530-4f7d-9432-47a136f7b66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ä¸­æ–‡åŠ©ç†ã€‚', additional_kwargs={}, response_metadata={}), HumanMessage(content='1+1 = ?', additional_kwargs={}, response_metadata={}), AIMessage(content='1+1 = 2', additional_kwargs={}, response_metadata={}), HumanMessage(content='æˆ‘åˆšæ‰é—®çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ', additional_kwargs={}, response_metadata={})]\n",
      "AIç­”å¤ï¼š ä½ åˆšæ‰é—®çš„é—®é¢˜æ˜¯â€œ1+1 = ?â€ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. å®šä¹‰ Promptï¼ŒåŒ…å«å†å²æ¶ˆæ¯å ä½ç¬¦\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ä¸­æ–‡åŠ©ç†ã€‚\"),\n",
    "        MessagesPlaceholder(\"history\"),   # å ä½ç¬¦ï¼šå†å²å¯¹è¯ä¼šæ³¨å…¥è¿™é‡Œ\n",
    "        (\"human\", \"{question}\")           # å½“å‰ç”¨æˆ·é—®é¢˜\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 2. æ„é€ å†å²æ¶ˆæ¯\n",
    "history = [\n",
    "    HumanMessage(content=\"1+1 = ?\"),\n",
    "    AIMessage(content=\"1+1 = 2\")\n",
    "]\n",
    "\n",
    "# 3. æ ¼å¼åŒ– Promptï¼ŒæŠŠå†å²æ¶ˆæ¯ + æ–°é—®é¢˜åˆå¹¶\n",
    "prompt_value = prompt.format_messages(history=history, question=\"æˆ‘åˆšæ‰é—®çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
    "print(prompt_value)\n",
    "\n",
    "# 4. å®šä¹‰å¤§æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    base_url=\"https://www.dmxapi.cn/v1\",\n",
    "    #api_key=\"\",  æ›¿æ¢ä¸ºä½ çš„ API Key \n",
    "    temperature=0)\n",
    "\n",
    "# 5. æ‰§è¡Œè°ƒç”¨\n",
    "response = llm.invoke(prompt_value)\n",
    "print(\"AIç­”å¤ï¼š\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991f26c-6ae5-464e-a7ac-1824e85e3e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "183180a5-ff63-485a-a591-1f92bdd26dde",
   "metadata": {},
   "source": [
    "# 4. å·¥å…·è°ƒç”¨ï¼ˆTool Callingï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df55eb6-997c-45ad-a479-f36afe9acb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool ....\n",
      "è°ƒç”¨å·¥å…·æœ€ç»ˆå›ç­”: 12 + 30 ç­‰äº 42ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import ToolMessage, AIMessage\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå·¥å…·ï¼šè®¡ç®—ä¸¤ä¸ªæ•°çš„å’Œ\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"è®¡ç®—ä¸¤ä¸ªæ•´æ•°çš„å’Œ\"\"\"\n",
    "    print(\"tool ....\")\n",
    "    return a + b\n",
    "\n",
    "# æ¨¡å‹ç»‘å®šå·¥å…·\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    base_url=\"https://www.dmxapi.cn/v1\",\n",
    "    #api_key=\"\",  æ›¿æ¢ä¸ºä½ çš„ API Key \n",
    "    temperature=0)\n",
    "\n",
    "llm_tools = llm.bind_tools([add])\n",
    "\n",
    "# ç”¨æˆ·æé—®\n",
    "user_input = \"è¯·å¸®æˆ‘ç®—ä¸€ä¸‹ 12 + 30 ç­‰äºå¤šå°‘ï¼Œå¦‚æœéœ€è¦å¯ä»¥ç”¨å·¥å…·ã€‚\"\n",
    "# ç¬¬ä¸€æ¬¡è°ƒç”¨æ¨¡å‹ â†’ å¯èƒ½è§¦å‘å·¥å…·è°ƒç”¨\n",
    "ai_msg = llm_tools.invoke(user_input)\n",
    "\n",
    "# å¦‚æœæ¨¡å‹è§¦å‘äº†å·¥å…·è°ƒç”¨\n",
    "if ai_msg.tool_calls:\n",
    "    for call in ai_msg.tool_calls:\n",
    "        if call[\"name\"] == \"add\":  # æ‰§è¡Œå·¥å…·\n",
    "            result = add.invoke(call[\"args\"])\n",
    "            tool_msg = ToolMessage(content=str(result), name=call[\"name\"], tool_call_id=call[\"id\"])\n",
    "            # å†æ¬¡è°ƒç”¨æ¨¡å‹ â†’ è®©å®ƒåŸºäºå·¥å…·ç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”\n",
    "            final_ai = llm_tools.invoke([(\"human\", user_input), ai_msg, tool_msg])\n",
    "            print(\"è°ƒç”¨å·¥å…·æœ€ç»ˆå›ç­”:\", final_ai.content)\n",
    "else:\n",
    "    # æ¨¡å‹å¯èƒ½ç›´æ¥å›ç­”\n",
    "    print(\"æœ€ç»ˆå›ç­”:\", ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b44a6b-01b9-4aee-9bb1-50287ece5371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f83c2b1-42bd-4cd2-9523-cce359c384a0",
   "metadata": {},
   "source": [
    "# 5. æµå¼è¾“å‡ºï¼ˆStreamingï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312c1e0-aba9-4c62-8b4b-94e4c9ba9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChainæ˜¯ä¸€ç§ç”¨äºæ„å»ºæ™ºèƒ½åº”ç”¨çš„æ¡†æ¶ï¼Œç‰¹åˆ«å…³æ³¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œç”Ÿæˆã€‚å®ƒé€šè¿‡é›†æˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå„ç§æ•°æ®æºï¼Œæ”¯æŒå¤æ‚çš„å¯¹è¯ç®¡ç†å’Œæ¨ç†èƒ½åŠ›ã€‚è¯¥æ¡†æ¶è¿˜æä¾›äº†å·¥å…·å’Œæ¥å£ï¼Œæ–¹ä¾¿å¼€å‘è€…æ„å»ºå’Œéƒ¨ç½²å¤šæ ·åŒ–çš„è¯­è¨€åº”ç”¨ã€‚"
     ]
    }
   ],
   "source": [
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "stream_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    base_url=\"https://www.dmxapi.cn/v1\",\n",
    "    #api_key=\"\",  æ›¿æ¢ä¸ºä½ çš„ API Key \n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "\n",
    "_ = stream_llm.invoke(\"è¯·ç”¨ä¸‰å¥è¯ä»‹ç»LangChainçš„æ ¸å¿ƒåŠŸèƒ½ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c958543-fd2c-4d73-be40-bde4958930d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9f4a152-d33b-450f-b59b-eaa07d44f4e6",
   "metadata": {},
   "source": [
    "# 6. æ‰¹å¤„ç†ä¸å¼‚æ­¥å¹¶å‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b54db4-68a7-4f10-a743-7d887464836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RAGï¼ˆRetrieval-Augmented Generationï¼‰æ˜¯ä¸€ç§ç»“åˆä¿¡æ¯æ£€ç´¢å’Œç”Ÿæˆæ¨¡å‹çš„æŠ€æœ¯ï¼Œç”¨äºæé«˜è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„æ€§èƒ½ã€‚', 'Agentæ˜¯èƒ½å¤Ÿè‡ªä¸»æ„ŸçŸ¥ç¯å¢ƒå¹¶é‡‡å–è¡ŒåŠ¨ä»¥å®ç°ç‰¹å®šç›®æ ‡çš„å®ä½“ã€‚', 'LangGraphæ˜¯ä¸€ç§ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†çš„å›¾ç»“æ„ï¼Œæ—¨åœ¨é€šè¿‡å›¾å½¢åŒ–æ–¹å¼è¡¨ç¤ºå’Œå¤„ç†è¯­è¨€æ•°æ®åŠå…¶å…³ç³»ã€‚']\n",
      "['RAGï¼ˆRetrieval-Augmented Generationï¼‰æ˜¯ä¸€ç§ç»“åˆä¿¡æ¯æ£€ç´¢å’Œç”Ÿæˆæ¨¡å‹çš„æŠ€æœ¯ï¼Œç”¨äºæé«˜è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„æ€§èƒ½ã€‚', 'Agentæ˜¯èƒ½å¤Ÿè‡ªä¸»æ„ŸçŸ¥ç¯å¢ƒå¹¶é‡‡å–è¡ŒåŠ¨ä»¥å®ç°ç‰¹å®šç›®æ ‡çš„å®ä½“ã€‚', 'LangGraphæ˜¯ä¸€ç§ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†çš„å›¾ç»“æ„ï¼Œæ—¨åœ¨é€šè¿‡å›¾å½¢åŒ–æ–¹å¼è¡¨ç¤ºå’Œå¤„ç†è¯­è¨€æ•°æ®åŠå…¶å…³ç³»ã€‚']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# æ¨¡å‹ç»‘å®šå·¥å…·\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    base_url=\"https://www.dmxapi.cn/v1\",\n",
    "    #api_key=\"\",  æ›¿æ¢ä¸ºä½ çš„ API Key \n",
    "    temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"ä¸€å¥è¯å›ç­”ï¼š{q}\")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "qs = [{\"q\": q} for q in [\"ä»€ä¹ˆæ˜¯RAGï¼Ÿ\", \"ä»€ä¹ˆæ˜¯Agentï¼Ÿ\", \"ä»€ä¹ˆæ˜¯LangGraphï¼Ÿ\"]]\n",
    "\n",
    "# åŒæ­¥\n",
    "print(chain.batch(qs))\n",
    "\n",
    "# å¼‚æ­¥ pyæ–‡ä»¶\n",
    "# async def run():\n",
    "#     rets = await chain.abatch(qs)\n",
    "#     print(rets)\n",
    "# asyncio.run(run())\n",
    "\n",
    "# å¼‚æ­¥ notebookæ–‡ä»¶\n",
    "rets = await chain.abatch(qs)\n",
    "print(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3ccd9-f855-4efa-9155-f970987bfb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b0c6d19-7e72-41a5-8ad6-d63f5e8a5a9f",
   "metadata": {},
   "source": [
    "# 7. LCEL åˆ†æ”¯ä¸å¹¶è¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46c133c5-9e5a-47a2-8d06-5589c5c02071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': 'LangChain æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„ LLM åº”ç”¨æ¡†æ¶ï¼Œæ—¨åœ¨æ„å»ºå¤æ‚çš„å¯¹è¯ç³»ç»Ÿã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œæ™ºèƒ½ä»£ç†ï¼ˆAgentï¼‰ç­‰åº”ç”¨ã€‚', 'points': '1. **æ¨¡å—åŒ–è®¾è®¡**ï¼šLangChain æä¾›äº†çµæ´»çš„æ¨¡å—åŒ–æ¶æ„ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿæ ¹æ®éœ€æ±‚ç»„åˆä¸åŒçš„ç»„ä»¶ï¼Œæ„å»ºå¤æ‚çš„å¯¹è¯ç³»ç»Ÿã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œæ™ºèƒ½ä»£ç†ï¼ˆAgentï¼‰ç­‰åº”ç”¨ã€‚\\n\\n2. **æ”¯æŒå¤šç§åŠŸèƒ½**ï¼šè¯¥æ¡†æ¶æ”¯æŒå¤šç§åŠŸèƒ½ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€ä¿¡æ¯æ£€ç´¢ã€ä¸Šä¸‹æ–‡ç®¡ç†å’Œä»»åŠ¡æ‰§è¡Œï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿå®ç°å¤æ‚çš„åº”ç”¨åœºæ™¯ã€‚\\n\\n3. **æ˜“äºé›†æˆ**ï¼šLangChain å¯ä»¥ä¸å¤šç§å¤–éƒ¨æ•°æ®æºå’Œ API é›†æˆï¼Œå¢å¼ºç³»ç»Ÿçš„èƒ½åŠ›å’Œçµæ´»æ€§ï¼Œé€‚ç”¨äºå„ç§è¡Œä¸šå’Œåº”ç”¨éœ€æ±‚ã€‚'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBranch, RunnableParallel\n",
    "\n",
    "summ = ChatPromptTemplate.from_template(\"ç”¨ä¸­æ–‡æ€»ç»“ï¼š{text}\")\n",
    "bullets = ChatPromptTemplate.from_template(\"åˆ—å‡ºä¸‰æ¡è¦ç‚¹ï¼š{text}\")\n",
    "\n",
    "parallel = RunnableParallel(\n",
    "    summary=summ | llm | StrOutputParser(),\n",
    "    points=bullets | llm | StrOutputParser(),\n",
    ")\n",
    "print(parallel.invoke({\"text\": \"LangChain æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„ LLM åº”ç”¨æ¡†æ¶ï¼Œç”¨äºæ„å»ºå¤æ‚å¯¹è¯ã€RAGã€Agent ç­‰ç³»ç»Ÿã€‚\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d886f-0168-47a6-93e0-285cf7aa4ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cd4a0dc-1527-4648-87f4-ab58ecc2c0a1",
   "metadata": {},
   "source": [
    "# 8. å¯æŒç»­è®°å¿†ï¼ˆRunnableWithMessageHistoryï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "622c2e75-fb4e-4521-99cd-60c41914c30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·ï¼šæˆ‘å«å¼ ä¸‰ã€‚\n",
      "AIï¼š ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "\n",
      " ç”¨æˆ·ï¼šæˆ‘å«ä»€ä¹ˆï¼Ÿ\n",
      "AIï¼š ä½ å«å¼ ä¸‰ã€‚æœ‰ä»€ä¹ˆæƒ³èŠçš„æˆ–è€…éœ€è¦å¸®åŠ©çš„å‘¢ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# å¯æŒç»­è®°å¿†ï¼šRunnableWithMessageHistory\n",
    "# =====================================================\n",
    "\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory  # å†…å­˜å‹æ¶ˆæ¯è®°å½•\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# å®šä¹‰å…¨å±€çš„â€œä¼šè¯å­˜å‚¨â€ï¼Œç”¨æ¥ä¿å­˜æ¯ä¸ª session çš„èŠå¤©å†å²\n",
    "#    ï¼ˆçœŸå®é¡¹ç›®ä¸­å¯æ”¹ä¸º Redisã€SQLite ç­‰ï¼‰\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    \"\"\"\n",
    "    æ ¹æ® session_id è·å–å¯¹åº”çš„å†å²æ¶ˆæ¯å¯¹è±¡ã€‚\n",
    "    å¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„ InMemoryChatMessageHistoryã€‚\n",
    "    \"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "# å®šä¹‰ Prompt æ¨¡æ¿\n",
    "#     - system: ç»™æ¨¡å‹è®¾å®šè§’è‰²\n",
    "#     - MessagesPlaceholder: å†å²æ¶ˆæ¯å°†æ³¨å…¥è¿™é‡Œ\n",
    "#     - human: å½“å‰ç”¨æˆ·è¾“å…¥\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ä¸­æ–‡åŠ©ç†ï¼Œä¼šæ ¹æ®ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚\"),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "#æ„å»ºåŸºæœ¬é“¾ï¼šPrompt â†’ LLM â†’ è¾“å‡ºè§£æ\n",
    "memory_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# å°†é“¾åŒ…è£…ä¸ºæ”¯æŒè®°å¿†çš„ç‰ˆæœ¬\n",
    "with_history = RunnableWithMessageHistory(\n",
    "    memory_chain,              # åŸå§‹é“¾\n",
    "    get_session_history,       # è·å–å†å²å‡½æ•°\n",
    "    input_messages_key=\"question\",  # å¯¹åº” prompt è¾“å…¥çš„ key\n",
    "    history_messages_key=\"history\", # å¯¹åº” MessagesPlaceholder çš„å˜é‡å\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# æ¨¡æ‹Ÿä¸€ä¸ªä¼šè¯ï¼Œç”¨ session_id åŒºåˆ†ä¸åŒç”¨æˆ·\n",
    "cfg = {\"configurable\": {\"session_id\": \"user-001\"}}\n",
    "\n",
    "# ç¬¬ä¸€æ¬¡æé—®ï¼šå‘Šè¯‰æ¨¡å‹â€œæˆ‘å«å¼ ä¸‰â€\n",
    "print(\"ç”¨æˆ·ï¼šæˆ‘å«å¼ ä¸‰ã€‚\")\n",
    "print(\"AIï¼š\", with_history.invoke({\"question\": \"æˆ‘å«å¼ ä¸‰ã€‚\"}, cfg))\n",
    "\n",
    "# ç¬¬äºŒæ¬¡æé—®ï¼šè®©æ¨¡å‹å›å¿†å‰é¢çš„å¯¹è¯\n",
    "print(\"\\n ç”¨æˆ·ï¼šæˆ‘å«ä»€ä¹ˆï¼Ÿ\")\n",
    "print(\"AIï¼š\", with_history.invoke({\"question\": \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\"}, cfg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eec8d4-e80e-472f-bbbd-abb92087d82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2c488c5-3484-463a-ac73-a4817b564aaf",
   "metadata": {},
   "source": [
    "# 9. ç®€å•RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4fb93-1eee-4595-a194-db32e0144eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs: [Document(id='69c1dd1f-bce0-419c-b13b-0577d2eee490', metadata={}, page_content='LangGraph ç”¨äºå¤šAgentåä½œä¸åˆ†æ”¯é€»è¾‘å»ºæ¨¡ã€‚'), Document(id='8cff42bf-2fe9-418c-99c9-7f22ccb9e4b0', metadata={}, page_content='LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„æ¡†æ¶ã€‚'), Document(id='f7eb9fa8-9ec6-4962-a2a3-dc8aa2f74121', metadata={}, page_content='LangFlow æ˜¯å¯è§†åŒ–æ‹–æ‹½å¼æ„å»ºå™¨ã€‚')]\n",
      "LangGraph æ˜¯ç”¨äºå¤šAgentåä½œä¸åˆ†æ”¯é€»è¾‘å»ºæ¨¡çš„å·¥å…·ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "docs = [\n",
    "    \"LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„æ¡†æ¶ã€‚\",\n",
    "    \"LangGraph ç”¨äºå¤šAgentåä½œä¸åˆ†æ”¯é€»è¾‘å»ºæ¨¡ã€‚\",\n",
    "    \"LangSmith ç”¨äºå¯è§‚æµ‹æ€§ä¸è¯„ä¼°ã€‚\",\n",
    "    \"LangFlow æ˜¯å¯è§†åŒ–æ‹–æ‹½å¼æ„å»ºå™¨ã€‚\"\n",
    "]\n",
    "splits = RecursiveCharacterTextSplitter(chunk_size=80, chunk_overlap=10).create_documents(docs)\n",
    "\n",
    "emb = OpenAIEmbeddings(\n",
    "    base_url=\"https://www.dmxapi.cn/v1\",\n",
    "    #api_key=\"\",  æ›¿æ¢ä¸ºä½ çš„ API Key \n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "vs = FAISS.from_documents(splits, emb)\n",
    "\n",
    "def retrieve(q, k=3): return vs.similarity_search(q, k=k)\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"å·²çŸ¥å†…å®¹ï¼š\\n{context}\\n---\\nå›ç­”é—®é¢˜ï¼š{question}\")\n",
    "def format_docs(ds): return \"\\n\".join([d.page_content for d in ds])\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªé—®ç­”å‡½æ•°ï¼Œå…ˆæ£€ç´¢ï¼Œå†é—®ç­”\n",
    "def rag_chain(question: str):\n",
    "    # Step 1: æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£\n",
    "    docs = retrieve(question)\n",
    "    print('docs:' , docs)\n",
    "    context = format_docs(docs)\n",
    "   \n",
    "\n",
    "    # Step 2: ç”Ÿæˆ Prompt\n",
    "    prompt_text = rag_prompt.format(context=context, question=question)\n",
    "\n",
    "    # Step 3: è°ƒç”¨æ¨¡å‹\n",
    "    response = llm.invoke(prompt_text)\n",
    "\n",
    "    # Step 4: æå–æ–‡æœ¬ç»“æœ\n",
    "    return response.content\n",
    "    \n",
    "print(rag_chain(\"LangGraph æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fb156-810a-4e4a-bc03-dd500728626b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baadf6de-b5f6-423b-a3da-83153e22d8fc",
   "metadata": {},
   "source": [
    "# 10. å®¹é”™ä¸å›é€€æœºåˆ¶ï¼ˆFallbackï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611ff9a-1d74-40de-a183-291a4fc755b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith æ˜¯ä¸€ä¸ªä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å’Œæœºå™¨å­¦ä¹ çš„å·¥å…·æˆ–å¹³å°ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…å’Œç ”ç©¶äººå‘˜æ›´é«˜æ•ˆåœ°æ„å»ºã€è®­ç»ƒå’Œéƒ¨ç½²è¯­è¨€æ¨¡å‹ã€‚å®ƒçš„ä¸»è¦ä½œç”¨åŒ…æ‹¬ï¼š\n",
      "\n",
      "1. **æ¨¡å‹è®­ç»ƒ**ï¼šæä¾›ç”¨æˆ·å‹å¥½çš„ç•Œé¢å’Œå·¥å…·ï¼Œç®€åŒ–è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿæ›´å¿«åœ°å®ç°æ¨¡å‹çš„è®­ç»ƒå’Œä¼˜åŒ–ã€‚\n",
      "\n",
      "2. **æ•°æ®ç®¡ç†**ï¼šå¸®åŠ©ç”¨æˆ·ç®¡ç†å’Œå¤„ç†è®­ç»ƒæ•°æ®ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…æ´—ã€æ ‡æ³¨å’Œå¢å¼ºç­‰åŠŸèƒ½ï¼Œä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
      "\n",
      "3. **è¯„ä¼°ä¸è°ƒä¼˜**ï¼šæä¾›è¯„ä¼°å·¥å…·ï¼Œå¸®åŠ©ç”¨æˆ·åˆ†ææ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶è¿›è¡Œå¿…è¦çš„è°ƒä¼˜ï¼Œä»¥è¾¾åˆ°æ›´å¥½çš„æ•ˆæœã€‚\n",
      "\n",
      "4. **é›†æˆä¸éƒ¨ç½²**ï¼šæ”¯æŒå°†è®­ç»ƒå¥½çš„æ¨¡å‹é›†æˆåˆ°åº”ç”¨ç¨‹åºä¸­ï¼Œå¹¶æä¾›éƒ¨ç½²æ–¹æ¡ˆï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å®é™…ç¯å¢ƒä¸­è¿è¡Œã€‚\n",
      "\n",
      "5. **ç¤¾åŒºä¸æ”¯æŒ**ï¼šé€šè¿‡ç¤¾åŒºæ”¯æŒå’Œæ–‡æ¡£ï¼Œå¸®åŠ©ç”¨æˆ·è§£å†³åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ï¼Œä¿ƒè¿›çŸ¥è¯†åˆ†äº«å’Œåˆä½œã€‚\n",
      "\n",
      "æ€»çš„æ¥è¯´ï¼ŒLangSmith æ—¨åœ¨é™ä½è‡ªç„¶è¯­è¨€å¤„ç†é¡¹ç›®çš„æŠ€æœ¯é—¨æ§›ï¼Œæé«˜å¼€å‘æ•ˆç‡ã€‚\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "å½“ä¸»æ¨¡å‹è¶…æ—¶ / æŠ¥é”™ / ä¸ç¨³å®š / ä»·æ ¼å¤ªè´µæ—¶ï¼Œ\n",
    "ç³»ç»Ÿå¯ä»¥è‡ªåŠ¨ã€Œåˆ‡æ¢ã€åˆ°å¦ä¸€ä¸ªå¤‡ç”¨æ¨¡å‹ç»§ç»­å›ç­”ï¼Œ\n",
    "è€Œä¸ä¼šè®©ç”¨æˆ·çœ‹åˆ° â€œè¯·æ±‚å¤±è´¥â€ çš„å°´å°¬åœºé¢ã€‚\n",
    "\"\"\"\n",
    "\n",
    "fallback_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini-legacy\",\n",
    "    base_url=\"https://www.dmxapi.cn/v1\",\n",
    "    #api_key=\"\",  æ›¿æ¢ä¸ºä½ çš„ API Key \n",
    ")\n",
    "\n",
    "robust_chain = (\n",
    "    ChatPromptTemplate.from_template(\"å›ç­”ï¼š{q}\")\n",
    "    | llm | StrOutputParser()\n",
    ").with_fallbacks([\n",
    "    ChatPromptTemplate.from_template(\"å›ç­”ç²¾ç®€ï¼š{q}\") | fallback_llm | StrOutputParser()\n",
    "])\n",
    "\n",
    "print(robust_chain.invoke({\"q\": \"ç®€è¿° LangSmith çš„ä½œç”¨\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb398f3-cdf2-4e16-9142-b44272699514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6bdc4b-83b3-4f67-a9c4-172b9c6e725a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
